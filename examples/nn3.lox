// Neural Network Implementation for X Pattern Recognition in Lox

class NeuralNetwork {
  init() {
    // Network structure: 9 inputs (3x3 grid), 6 hidden neurons, 1 output
    this.inputSize = 9;
    this.hiddenSize = 6;
    this.outputSize = 1;
    this.learningRate = 0.25;

    // Xavier/Glorot initialization
    var inputScale = sqrt(2.0 / this.inputSize);
    var hiddenScale = sqrt(2.0 / this.hiddenSize);

    // Initialize input to hidden weights
    this.weightsInputHidden = Array(this.hiddenSize);
    for (var i = 0; i < this.hiddenSize; i = i + 1) {
      var hiddenWeights = Array(this.inputSize);
      for (var j = 0; j < this.inputSize; j = j + 1) {
        hiddenWeights.set(j, this.randomrange(-inputScale, inputScale));
      }
      this.weightsInputHidden.set(i, hiddenWeights);
    }

    // Initialize hidden to output weights
    this.weightsHiddenOutput = Array(this.outputSize);
    for (var i = 0; i < this.outputSize; i = i + 1) {
      var outputWeights = Array(this.hiddenSize);
      for (var j = 0; j < this.hiddenSize; j = j + 1) {
        outputWeights.set(j, this.randomrange(-hiddenScale, hiddenScale));
      }
      this.weightsHiddenOutput.set(i, outputWeights);
    }

    // Initialize biases to 0
    this.biasHidden = Array(this.hiddenSize);
    for (var i = 0; i < this.hiddenSize; i = i + 1) {
      this.biasHidden.set(i, 0);
    }

    this.biasOutput = Array(this.outputSize);
    for (var i = 0; i < this.outputSize; i = i + 1) {
      this.biasOutput.set(i, 0);
    }
  }

  randomrange(min, max) {
    return min + (max - min) * random();
  }

  // Activation function - using tanh instead of sigmoid for better gradient flow
  activate(x) {
    return tanh(x);  // tanh has range (-1, 1) instead of (0, 1)
  }

  // Derivative of tanh(x) is 1 - tanhÂ²(x)
  activateDerivative(x) {
    var t = tanh(x);
    return 1.0 - (t * t);
  }

  // Helper function to clamp values for numerical stability
  clamp(x, minVal, maxVal) {
    return min(max(x, minVal), maxVal);
  }

  forward(inputs) {
    // Hidden layer
    this.hiddenInputs = Array(this.hiddenSize);
    this.hiddenOutputs = Array(this.hiddenSize);
    
    for (var i = 0; i < this.hiddenSize; i = i + 1) {
      var sum = this.biasHidden.get(i);
      for (var j = 0; j < this.inputSize; j = j + 1) {
        sum = sum + inputs.get(j) * this.weightsInputHidden.get(i).get(j);
      }
      // Clamp sum for numerical stability
      sum = this.clamp(sum, -10.0, 10.0);
      this.hiddenInputs.set(i, sum);
      this.hiddenOutputs.set(i, this.activate(sum));
    }

    // Output layer
    this.outputInput = this.biasOutput.get(0);
    for (var i = 0; i < this.hiddenSize; i = i + 1) {
      this.outputInput = this.outputInput + 
        this.hiddenOutputs.get(i) * this.weightsHiddenOutput.get(0).get(i);
    }
    // Clamp output and scale from (-1,1) to (0,1) range
    this.outputInput = this.clamp(this.outputInput, -10.0, 10.0);
    var tanhOutput = this.activate(this.outputInput);
    this.output = (tanhOutput + 1.0) * 0.5;  // Scale from (-1,1) to (0,1)

    return this.output;
  }

  train(inputs, target) {
    // Forward pass
    var prediction = this.forward(inputs);
    
    // Compute gradients for output layer
    // Scale target to (-1,1) range for tanh
    var scaledTarget = target * 2.0 - 1.0;
    // Get the tanh output before scaling
    var tanhOutput = this.activate(this.outputInput);
    var outputError = scaledTarget - tanhOutput;
    var outputDelta = outputError * this.activateDerivative(this.outputInput);
    
    // Compute gradients for hidden layer
    var hiddenDeltas = Array(this.hiddenSize);
    for (var i = 0; i < this.hiddenSize; i = i + 1) {
      var hiddenError = outputDelta * this.weightsHiddenOutput.get(0).get(i);
      hiddenDeltas.set(i, hiddenError * this.activateDerivative(this.hiddenInputs.get(i)));
    }
    
    // Update hidden to output weights
    for (var i = 0; i < this.hiddenSize; i = i + 1) {
      var oldWeight = this.weightsHiddenOutput.get(0).get(i);
      var adjustment = this.learningRate * outputDelta * this.hiddenOutputs.get(i);
      this.weightsHiddenOutput.get(0).set(i, oldWeight + adjustment);
    }
    
    // Update input to hidden weights
    for (var i = 0; i < this.hiddenSize; i = i + 1) {
      for (var j = 0; j < this.inputSize; j = j + 1) {
        var oldWeight = this.weightsInputHidden.get(i).get(j);
        var adjustment = this.learningRate * hiddenDeltas.get(i) * inputs.get(j);
        this.weightsInputHidden.get(i).set(j, oldWeight + adjustment);
      }
    }
    
    // Update biases
    this.biasOutput.set(0, this.biasOutput.get(0) + this.learningRate * outputDelta);
    for (var i = 0; i < this.hiddenSize; i = i + 1) {
      this.biasHidden.set(i, this.biasHidden.get(i) + this.learningRate * hiddenDeltas.get(i));
    }

    return 0.5 * outputError * outputError;
  }

  trainEpoch() {
    var totalError = 0;

    // Training data: X pattern (1) and non-X patterns (0)
    
    // X pattern:
    // 1 0 1
    // 0 1 0
    // 1 0 1
    var xPattern = Array(9);
    xPattern.set(0, 1); xPattern.set(1, 0); xPattern.set(2, 1);
    xPattern.set(3, 0); xPattern.set(4, 1); xPattern.set(5, 0);
    xPattern.set(6, 1); xPattern.set(7, 0); xPattern.set(8, 1);
    totalError = totalError + this.train(xPattern, 1);

    // Horizontal line (not X):
    // 0 0 0
    // 1 1 1
    // 0 0 0
    var hLine = Array(9);
    hLine.set(0, 0); hLine.set(1, 0); hLine.set(2, 0);
    hLine.set(3, 1); hLine.set(4, 1); hLine.set(5, 1);
    hLine.set(6, 0); hLine.set(7, 0); hLine.set(8, 0);
    totalError = totalError + this.train(hLine, 0);

    // Vertical line (not X):
    // 0 1 0
    // 0 1 0
    // 0 1 0
    var vLine = Array(9);
    vLine.set(0, 0); vLine.set(1, 1); vLine.set(2, 0);
    vLine.set(3, 0); vLine.set(4, 1); vLine.set(5, 0);
    vLine.set(6, 0); vLine.set(7, 1); vLine.set(8, 0);
    totalError = totalError + this.train(vLine, 0);

    // Empty pattern (not X):
    // 0 0 0
    // 0 0 0
    // 0 0 0
    var empty = Array(9);
    for (var i = 0; i < 9; i = i + 1) {
      empty.set(i, 0);
    }
    totalError = totalError + this.train(empty, 0);

    return totalError;
  }

  printPattern(pattern) {
    print pattern.get(0) + " " + pattern.get(1) + " " + pattern.get(2);
    print pattern.get(3) + " " + pattern.get(4) + " " + pattern.get(5);
    print pattern.get(6) + " " + pattern.get(7) + " " + pattern.get(8);
    print "";
  }
}

var nn = NeuralNetwork();

// Training parameters
var epoch = 0;
var nextPrint = 0;
var maxEpochs = 5000;
var errorThreshold = 0.001;

// Training loop
while (epoch < maxEpochs) {
  var error = nn.trainEpoch();
  
  if (epoch == nextPrint) {
    print "Epoch " + epoch + " Error: " + error;
    nextPrint = nextPrint + 500;
  }

  if (error < errorThreshold) {
    print "Converged at epoch " + epoch + " with error " + error;
    break;
  }

  epoch = epoch + 1;
}

print "Testing patterns:";

// Test X pattern
var xTest = Array(9);
xTest.set(0, 1); xTest.set(1, 0); xTest.set(2, 1);
xTest.set(3, 0); xTest.set(4, 1); xTest.set(5, 0);
xTest.set(6, 1); xTest.set(7, 0); xTest.set(8, 1);
print "X pattern:";
nn.printPattern(xTest);
print "Output: " + nn.forward(xTest);

// Test horizontal line
var hTest = Array(9);
hTest.set(0, 0); hTest.set(1, 0); hTest.set(2, 0);
hTest.set(3, 1); hTest.set(4, 1); hTest.set(5, 1);
hTest.set(6, 0); hTest.set(7, 0); hTest.set(8, 0);
print "Horizontal line:";
nn.printPattern(hTest);
print "Output: " + nn.forward(hTest);

// Test different X-like pattern
var xLike = Array(9);
xLike.set(0, 1); xLike.set(1, 0); xLike.set(2, 1);
xLike.set(3, 0); xLike.set(4, 0); xLike.set(5, 0);
xLike.set(6, 1); xLike.set(7, 0); xLike.set(8, 1);
print "X-like pattern (missing center):";
nn.printPattern(xLike);
print "Output: " + nn.forward(xLike);